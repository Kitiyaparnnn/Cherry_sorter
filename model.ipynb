{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loaded dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load image datasets\n",
    "def load_image_dataset(image_dir1, image_dir2, image_size=(224, 224)):\n",
    "    \"\"\"Loads image datasets from two directories with corresponding labels.\n",
    "\n",
    "    Args:\n",
    "        image_dir1: Path to the first directory containing images.\n",
    "        image_dir2: Path to the second directory containing images.\n",
    "        image_size: Tuple specifying the desired image size (width, height).\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing the image data (NumPy array) and labels (NumPy array).\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for filename in os.listdir(image_dir1):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            filepath = os.path.join(image_dir1, filename)\n",
    "            try:\n",
    "                img = Image.open(filepath).convert(\"RGB\").resize(image_size)\n",
    "                img_array = np.array(img) / 255.0 # Normalize pixel values\n",
    "                images.append(img_array)\n",
    "                labels.append(0) # Label for images from the first directory\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {filename}: {e}\")\n",
    "\n",
    "    for filename in os.listdir(image_dir2):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            filepath = os.path.join(image_dir2, filename)\n",
    "            try:\n",
    "                img = Image.open(filepath).convert(\"RGB\").resize(image_size)\n",
    "                img_array = np.array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1) # Label for images from the second directory\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {filename}: {e}\")\n",
    "                \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Function to split dataset\n",
    "def split_dataset(images, labels, test_size=0.2, val_size=0.1, random_state=42):\n",
    "    \"\"\"Splits the image dataset into training, testing, and validation sets.\"\"\"\n",
    "    x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=test_size, random_state=random_state, stratify=labels)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=val_size / (1 - test_size), random_state=random_state, stratify=y_train)\n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage (Replace with your actual directories)\n",
    "image_dir1 = \"/Users/kitiya/Works/cherry_sorter/cherry_coffee/not_good\"\n",
    "image_dir2 = \"/Users/kitiya/Works/cherry_sorter/cherry_coffee/good\"\n",
    "images, labels = load_image_dataset(image_dir1, image_dir2)\n",
    "x_train, y_train, x_val, y_val, x_test, y_test = split_dataset(images, labels)\n",
    "\n",
    "# Print dataset sizes\n",
    "print(\"Training set size:\", len(x_train))\n",
    "print(\"Validation set size:\", len(x_val))\n",
    "print(\"Testing set size:\", len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "def create_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(img_height, img_width, 3)),  # Input shape for RGB images\n",
    "        layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Define image dimensions\n",
    "img_height = 224  # Example dimensions, adjust as needed\n",
    "img_width = 224\n",
    "\n",
    "# Create the model\n",
    "model = create_model()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define a ModelCheckpoint callback\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\"best_model.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=16,\n",
    "          epochs=10,  # Adjust number of epochs as needed\n",
    "          validation_data=(x_val, y_val),\n",
    "          callbacks=[checkpoint])\n",
    "\n",
    "# Evaluate the model\n",
    "_, accuracy = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert to .tflite**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model as .tflite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(\"model.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with captured image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "image_size = (224, 224)\n",
    "path = \"/test.jpg\"\n",
    "\n",
    "# Load, convert, and resize the image\n",
    "img = Image.open(path).convert(\"RGB\").resize(image_size)\n",
    "img_array = np.array(img) / 255.0\n",
    "\n",
    "# Add a batch dimension\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "print(\"image size: \", img_array.shape)\n",
    "\n",
    "# Load the TFLite model and allocate tensors\n",
    "interpreter = tf.lite.Interpreter(model_path=\"best_model.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "print(\"input: \\n\", input_details)\n",
    "print(\"output: \\n\", output_details)\n",
    "\n",
    "# Function for making predictions\n",
    "def predict_tflite(image):\n",
    "    interpreter.set_tensor(input_details[0]['index'], image)\n",
    "    interpreter.invoke()\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    prediction = np.argmax(output_data)\n",
    "    return \"Class 1\" if prediction == 1 else \"Class 0\"\n",
    "\n",
    "# Make the prediction\n",
    "prediction = predict_tflite(img_array.astype(np.float32))\n",
    "print(\"Prediction:\", prediction)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
