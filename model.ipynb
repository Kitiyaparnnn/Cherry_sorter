{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loaded dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load image datasets\n",
    "def load_image_dataset(image_dir1, image_dir2, image_size=(224, 224)):\n",
    "    \"\"\"Loads image datasets from two directories with corresponding labels.\n",
    "\n",
    "    Args:\n",
    "        image_dir1: Path to the first directory containing images.\n",
    "        image_dir2: Path to the second directory containing images.\n",
    "        image_size: Tuple specifying the desired image size (width, height).\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing the image data (NumPy array) and labels (NumPy array).\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for filename in os.listdir(image_dir1):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            filepath = os.path.join(image_dir1, filename)\n",
    "            try:\n",
    "                img = Image.open(filepath).convert(\"RGB\").resize(image_size)\n",
    "                img_array = np.array(img) / 255.0 # Normalize pixel values\n",
    "                images.append(img_array)\n",
    "                labels.append(0) # Label for images from the first directory\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {filename}: {e}\")\n",
    "\n",
    "    for filename in os.listdir(image_dir2):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            filepath = os.path.join(image_dir2, filename)\n",
    "            try:\n",
    "                img = Image.open(filepath).convert(\"RGB\").resize(image_size)\n",
    "                img_array = np.array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1) # Label for images from the second directory\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {filename}: {e}\")\n",
    "                \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Function to split dataset\n",
    "def split_dataset(images, labels, test_size=0.2, val_size=0.1, random_state=42):\n",
    "    \"\"\"Splits the image dataset into training, testing, and validation sets.\"\"\"\n",
    "    x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=test_size, random_state=random_state, stratify=labels)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=val_size / (1 - test_size), random_state=random_state, stratify=y_train)\n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 296\n",
      "Validation set size: 43\n",
      "Testing set size: 85\n"
     ]
    }
   ],
   "source": [
    "# Example usage (Replace with your actual directories)\n",
    "image_dir1 = \"./cherry_coffee/not_good\"\n",
    "image_dir2 = \"./cherry_coffee/good\"\n",
    "images, labels = load_image_dataset(image_dir1, image_dir2)\n",
    "x_train, y_train, x_val, y_val, x_test, y_test = split_dataset(images, labels)\n",
    "\n",
    "# Print dataset sizes\n",
    "print(\"Training set size:\", len(x_train))\n",
    "print(\"Validation set size:\", len(x_val))\n",
    "print(\"Testing set size:\", len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05 10:24:13.849075: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2024-11-05 10:24:13.849122: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-11-05 10:24:13.849135: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-11-05 10:24:13.849544: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-11-05 10:24:13.849932: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05 10:24:14.570988: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 1.4721 - accuracy: 0.5473\n",
      "Epoch 1: val_accuracy improved from -inf to 0.69767, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05 10:24:16.235837: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "/opt/anaconda3/envs/mlp/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 2s 87ms/step - loss: 1.4721 - accuracy: 0.5473 - val_loss: 0.6641 - val_accuracy: 0.6977\n",
      "Epoch 2/10\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.6322 - accuracy: 0.6806\n",
      "Epoch 2: val_accuracy did not improve from 0.69767\n",
      "19/19 [==============================] - 1s 63ms/step - loss: 0.6326 - accuracy: 0.6824 - val_loss: 0.5975 - val_accuracy: 0.6977\n",
      "Epoch 3/10\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.6348 - accuracy: 0.7083\n",
      "Epoch 3: val_accuracy did not improve from 0.69767\n",
      "19/19 [==============================] - 1s 62ms/step - loss: 0.6380 - accuracy: 0.7061 - val_loss: 0.7409 - val_accuracy: 0.6977\n",
      "Epoch 4/10\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.6185 - accuracy: 0.7014\n",
      "Epoch 4: val_accuracy did not improve from 0.69767\n",
      "19/19 [==============================] - 1s 64ms/step - loss: 0.6116 - accuracy: 0.7061 - val_loss: 0.7062 - val_accuracy: 0.6977\n",
      "Epoch 5/10\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.5847 - accuracy: 0.7639\n",
      "Epoch 5: val_accuracy did not improve from 0.69767\n",
      "19/19 [==============================] - 1s 62ms/step - loss: 0.5961 - accuracy: 0.7500 - val_loss: 0.5238 - val_accuracy: 0.6977\n",
      "Epoch 6/10\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.4083 - accuracy: 0.8264\n",
      "Epoch 6: val_accuracy improved from 0.69767 to 0.83721, saving model to best_model.h5\n",
      "19/19 [==============================] - 1s 67ms/step - loss: 0.4168 - accuracy: 0.8243 - val_loss: 0.4445 - val_accuracy: 0.8372\n",
      "Epoch 7/10\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.3274 - accuracy: 0.8438\n",
      "Epoch 7: val_accuracy improved from 0.83721 to 0.86047, saving model to best_model.h5\n",
      "19/19 [==============================] - 1s 71ms/step - loss: 0.3270 - accuracy: 0.8446 - val_loss: 0.3221 - val_accuracy: 0.8605\n",
      "Epoch 8/10\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.2449 - accuracy: 0.8958\n",
      "Epoch 8: val_accuracy did not improve from 0.86047\n",
      "19/19 [==============================] - 1s 63ms/step - loss: 0.2410 - accuracy: 0.8986 - val_loss: 0.3140 - val_accuracy: 0.8605\n",
      "Epoch 9/10\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.2128 - accuracy: 0.8924\n",
      "Epoch 9: val_accuracy improved from 0.86047 to 0.90698, saving model to best_model.h5\n",
      "19/19 [==============================] - 1s 67ms/step - loss: 0.2085 - accuracy: 0.8953 - val_loss: 0.2995 - val_accuracy: 0.9070\n",
      "Epoch 10/10\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.3160 - accuracy: 0.8854\n",
      "Epoch 10: val_accuracy did not improve from 0.90698\n",
      "19/19 [==============================] - 1s 64ms/step - loss: 0.3089 - accuracy: 0.8885 - val_loss: 0.3408 - val_accuracy: 0.8837\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.3409 - accuracy: 0.8471\n",
      "Test accuracy: 0.8470588326454163\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "def create_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(img_height, img_width, 3)),  # Input shape for RGB images\n",
    "        layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Define image dimensions\n",
    "img_height = 224  # Example dimensions, adjust as needed\n",
    "img_width = 224\n",
    "\n",
    "# Create the model\n",
    "model = create_model()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define a ModelCheckpoint callback\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\"best_model.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=16,\n",
    "          epochs=10,  # Adjust number of epochs as needed\n",
    "          validation_data=(x_val, y_val),\n",
    "          callbacks=[checkpoint])\n",
    "\n",
    "# Evaluate the model\n",
    "_, accuracy = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert to .tflite**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/5t/qhv6pkk115b3_mpr1bbc5c9c0000gn/T/tmpqe6p7uxm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/5t/qhv6pkk115b3_mpr1bbc5c9c0000gn/T/tmpqe6p7uxm/assets\n",
      "2024-11-05 10:24:32.245424: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2024-11-05 10:24:32.245606: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2024-11-05 10:24:32.246355: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /var/folders/5t/qhv6pkk115b3_mpr1bbc5c9c0000gn/T/tmpqe6p7uxm\n",
      "2024-11-05 10:24:32.247252: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2024-11-05 10:24:32.247257: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /var/folders/5t/qhv6pkk115b3_mpr1bbc5c9c0000gn/T/tmpqe6p7uxm\n",
      "2024-11-05 10:24:32.249498: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
      "2024-11-05 10:24:32.250427: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2024-11-05 10:24:32.404159: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /var/folders/5t/qhv6pkk115b3_mpr1bbc5c9c0000gn/T/tmpqe6p7uxm\n",
      "2024-11-05 10:24:32.414279: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 167923 microseconds.\n",
      "2024-11-05 10:24:32.439755: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    }
   ],
   "source": [
    "# Save the model as .tflite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(\"model.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with captured image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image size:  (1, 224, 224, 3)\n",
      "input: \n",
      " [{'name': 'serving_default_input_1:0', 'index': 0, 'shape': array([  1, 224, 224,   3], dtype=int32), 'shape_signature': array([ -1, 224, 224,   3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "output: \n",
      " [{'name': 'StatefulPartitionedCall:0', 'index': 21, 'shape': array([1, 1], dtype=int32), 'shape_signature': array([-1,  1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "Prediction: Class 0\n"
     ]
    }
   ],
   "source": [
    "# load image\n",
    "image_size = (224, 224)\n",
    "path = \"/test.jpg\"\n",
    "\n",
    "# Load, convert, and resize the image\n",
    "img = Image.open(path).convert(\"RGB\").resize(image_size)\n",
    "img_array = np.array(img) / 255.0\n",
    "\n",
    "# Add a batch dimension\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "print(\"image size: \", img_array.shape)\n",
    "\n",
    "# Load the TFLite model and allocate tensors\n",
    "interpreter = tf.lite.Interpreter(model_path=\"model.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "print(\"input: \\n\", input_details)\n",
    "print(\"output: \\n\", output_details)\n",
    "\n",
    "# Function for making predictions\n",
    "def predict_tflite(image):\n",
    "    interpreter.set_tensor(input_details[0]['index'], image)\n",
    "    interpreter.invoke()\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    prediction = np.argmax(output_data)\n",
    "    return \"Class 1\" if prediction == 1 else \"Class 0\"\n",
    "\n",
    "# Make the prediction\n",
    "prediction = predict_tflite(img_array.astype(np.float32))\n",
    "print(\"Prediction:\", prediction)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
